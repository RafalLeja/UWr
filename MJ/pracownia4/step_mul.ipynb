{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(3407)\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265*165=165*200+165*60+165*5=33000+9900+825=43725\n"
     ]
    }
   ],
   "source": [
    "def step_mul(length):\n",
    "    a = [random.randint(0,9) for i in range(length)]\n",
    "    b = [random.randint(0,9) for i in range(length)]\n",
    "    val_a = int(''.join(str(d) for d in a))\n",
    "    val_b = int(''.join(str(d) for d in b))\n",
    "    if val_a < val_b:\n",
    "        val_a, val_b = val_b, val_a\n",
    "        a, b = b, a\n",
    "    \n",
    "    steps = [f\"{val_a}*{val_b}=\"]\n",
    "    steps_eq = []\n",
    "    for i in range(length):\n",
    "        a_i = a[i] * 10**(length-i-1)\n",
    "        steps.append(f\"{val_b}*{a_i}+\")\n",
    "        steps_eq.append(str(val_b * a_i) + \"+\")\n",
    "    \n",
    "    steps[-1] = steps[-1][:-1] + \"=\"\n",
    "    steps_eq[-1] = steps_eq[-1][:-1] + \"=\"\n",
    "\n",
    "    steps.extend(steps_eq)\n",
    "    steps.append(str(val_a * val_b))\n",
    "    out = ''.join(steps)\n",
    "    return out\n",
    "    # print(out)\n",
    "\n",
    "step_mul(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulDataset(Dataset):\n",
    "    \"\"\" \n",
    "    Dataset for the Add problem. E.g. for problem length 3:\n",
    "    12 + 333 = 345\n",
    "    Input: 0 1 2 3 3 3 -> Output: 0 3 4 5\n",
    "    Which will feed into the transformer concatenated as:\n",
    "    input:  0 1 2 3 3 3 0 3 4\n",
    "    output: I I I I I 0 3 4 5\n",
    "    where I is \"ignore\", as the transformer is reading the input sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split, length=3):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return 13\n",
    "    \n",
    "    def get_block_size(self):\n",
    "        # the length of the sequence that will feed into transformer, \n",
    "        # containing concatenated input and the output, but -1 because\n",
    "        # the transformer starts making predictions at the last input element\n",
    "        return 4 * self.length - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            rai = random_mul_instance(self.length)\n",
    "            h = hash(str(rai[:2*self.length]))\n",
    "            \n",
    "            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n",
    "            if inp_split == self.split:\n",
    "                break # ok\n",
    "        \n",
    "        x = torch.tensor(rai[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(rai[1:], dtype=torch.long)\n",
    "        \n",
    "        # we only want to predict at output locations, mask out the loss at the input locations\n",
    "        y[:2*self.length-1] = -1\n",
    "        return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
