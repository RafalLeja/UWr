{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578c63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prych/.local/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.sso.sso_relationship.bias', 'cls.sso.sso_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Bardzo', 'lubię', 'lody', 'mali', 'nowe', 'z', 'bi', 'tą', 'śmietan', 'ą', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"allegro/herbert-base-cased\"\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "text = 'Bardzo lubię lody malinowe z bitą śmietaną.'\n",
    "\n",
    "token_ids = tokenizer(text, return_tensors='pt')['input_ids'][0]\n",
    "\n",
    "print ([tokenizer.decode(idx) for idx in token_ids])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd86d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#lines = open('data/reviews_for_task3.txt').readlines()\n",
    "\n",
    "def representation(L):\n",
    "    txt = ' '.join(L)\n",
    "    input_ids = tokenizer(txt, return_tensors='pt')['input_ids'].to(device)\n",
    "    output = model(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]\n",
    "\n",
    "def spoil(L):\n",
    "    res = []\n",
    "    for w in L:\n",
    "        if random.random() < 0.85:\n",
    "            res.append(w)\n",
    "        else:\n",
    "            res.append(w.upper())\n",
    "    return res\n",
    "\n",
    "lines = []\n",
    "\n",
    "for x in open('data/dobre.txt'):\n",
    "    lines.append('GOOD ' + x.strip())\n",
    "for x in open('data/zle.txt'):\n",
    "    lines.append('BAD ' + x.strip())\n",
    "    \n",
    "random.shuffle(lines)\n",
    "\n",
    "N = len(lines)\n",
    "test_size = N // 4\n",
    "train_size = N - test_size\n",
    "\n",
    "train_lines = lines[:train_size]\n",
    "test_lines = lines[train_size:]\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for line in train_lines:\n",
    "    L = line.split()\n",
    "    y = 0 if L[0] == 'BAD' else 1\n",
    "    \n",
    "    x = representation(L[1:])\n",
    "    y_train.append(y)\n",
    "    X_train.append(x)\n",
    "    \n",
    "    for i in range(3):\n",
    "        x = representation(spoil(L[1:]))\n",
    "        y_train.append(y)\n",
    "        X_train.append(x)\n",
    "    \n",
    "    if len(X_train) % 100 == 0:\n",
    "        print (len(X_train))\n",
    "\n",
    "for line in test_lines:\n",
    "    L = line.split()\n",
    "    y = 0 if L[0] == 'BAD' else 1\n",
    "    \n",
    "    x = representation(L[1:])\n",
    "    y_test.append(y)\n",
    "    X_test.append(x)\n",
    "        \n",
    "    if len(X_test) % 100 == 0:\n",
    "        print (len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a5af9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(lines)\n",
    "test_size = N // 4\n",
    "train_size = N - test_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "803d8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9278529626920263\n",
      "Test accuracy: 0.8594950603732162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prych/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm \n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print ('Train accuracy:', clf.score(X_train, y_train))\n",
    "print ('Test accuracy:', clf.score(X_test, y_test))\n",
    "\n",
    "#Train accuracy: 0.9348939283101683\n",
    "#Test accuracy: 0.8715697036223929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33317a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}